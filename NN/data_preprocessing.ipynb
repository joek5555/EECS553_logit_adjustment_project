{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for creating a dataset from the MSCAD .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dataframe object that holds all the data for each different label. Then we will do a training/validation split on each of these separate dataframes. Finally we combine all the dataframes together. This ensures that all the instances of each label is split well between the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit this to be the path to the MSCAD.csv file\n",
    "csv_df = pd.read_csv(\"archive/MSCAD.csv\")\n",
    "\n",
    "val_split = 0.20 # what percent of the data will be validation data\n",
    "\n",
    "# create a data frame for each label\n",
    "brute_force_df = csv_df.loc[csv_df['Label'] == \"Brute_Force\"]\n",
    "brute_force_df = brute_force_df.loc[:, brute_force_df.columns != \"Label\"]\n",
    "brute_force_labels = ([\"Brute_Force\"]*brute_force_df.shape[0])\n",
    "http_ddos_df = csv_df.loc[csv_df['Label'] == \"HTTP_DDoS\"]\n",
    "http_ddos_df = http_ddos_df.loc[:, http_ddos_df.columns != \"Label\"]\n",
    "http_ddos_labels = ([\"HTTP_DDoS\"]*http_ddos_df.shape[0])\n",
    "icmp_flood_df = csv_df.loc[csv_df['Label'] == \"ICMP_Flood\"]\n",
    "icmp_flood_df = icmp_flood_df.loc[:, icmp_flood_df.columns != \"Label\"]\n",
    "icmp_flood_labels = [\"ICMP_Flood\"]*icmp_flood_df.shape[0]\n",
    "port_scan_df = csv_df.loc[csv_df['Label'] == \"Port_Scan\"]\n",
    "port_scan_df = port_scan_df.loc[:, port_scan_df.columns != \"Label\"]\n",
    "port_scan_labels = ([\"Port_Scan\"]*port_scan_df.shape[0])\n",
    "web_crawling_df = csv_df.loc[csv_df['Label'] == \"Web_Crwling\"]\n",
    "web_crawling_df = web_crawling_df.loc[:, web_crawling_df.columns != \"Label\"]\n",
    "web_crawling_labels = [\"Web_Crwling\"]*web_crawling_df.shape[0]\n",
    "normal_df = csv_df.loc[csv_df['Label'] == \"Normal\"]\n",
    "normal_df = normal_df.loc[:, normal_df.columns != \"Label\"]\n",
    "normal_labels = ([\"Normal\"]*normal_df.shape[0])\n",
    "\n",
    "features = [brute_force_df, http_ddos_df, icmp_flood_df, port_scan_df, web_crawling_df, normal_df]\n",
    "labels = [brute_force_labels, http_ddos_labels, icmp_flood_labels, port_scan_labels, web_crawling_labels, normal_labels]\n",
    "\n",
    "\n",
    "features_train_list = []\n",
    "labels_train_list = []\n",
    "features_val_list = []\n",
    "labels_val_list = []\n",
    "# for each label, split its dataframe into a training and test set\n",
    "for idx in range(len(features)):\n",
    "    features_train, features_val, labels_train, labels_val = train_test_split(features[idx], labels[idx], test_size=val_split)\n",
    "    features_train_list.append(features_train)\n",
    "    labels_train_list.append(labels_train)\n",
    "    features_val_list.append(features_val)\n",
    "    labels_val_list.append(labels_val)\n",
    "\n",
    "features_train_df = None\n",
    "labels_train_df = []\n",
    "features_val_df = None\n",
    "labels_val_df = []\n",
    "# combine all the training dataframes together and all the validation dataframes together\n",
    "for idx_label in range(len(features_train_list)):\n",
    "    features_train_df = pd.concat([features_train_df, features_train_list[idx_label]])\n",
    "    labels_train_df.extend(labels_train_list[idx_label])\n",
    "    features_val_df = pd.concat([features_val_df, features_val_list[idx_label]])\n",
    "    labels_val_df.extend(labels_val_list[idx_label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training, \n",
      "unique: ['Brute_Force' 'HTTP_DDoS' 'ICMP_Flood' 'Normal' 'Port_Scan' 'Web_Crwling'] \n",
      "counts: [70801   512    36 22801  8864    22]\n",
      "validation, \n",
      "unique: ['Brute_Force' 'HTTP_DDoS' 'ICMP_Flood' 'Normal' 'Port_Scan' 'Web_Crwling'] \n",
      "counts: [17701   129     9  5701  2217     6]\n"
     ]
    }
   ],
   "source": [
    "# ensure that each label is represented in both the training and validation data\n",
    "unique, counts = np.unique(labels_train_df, return_counts=True)\n",
    "unique2, counts2 = np.unique(labels_val_df, return_counts=True)\n",
    "print(f\"training, \\nunique: {unique} \\ncounts: {counts}\")\n",
    "print(f\"validation, \\nunique: {unique2} \\ncounts: {counts2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels from strings to numbers \n",
    "0 = \"Brute_Force\"\n",
    "1 = \"HTTP_DDoS\"\n",
    "2 = \"ICMP_Flood\"\n",
    "3 = \"Port_Scan\"\n",
    "4 = \"Web_Crwling\"\n",
    "5 = \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_np = np.array(features_train_df)\n",
    "\n",
    "for idx in range(len(labels_train_df)):\n",
    "    if labels_train_df[idx] == \"Brute_Force\":\n",
    "        labels_train_df[idx] = 0\n",
    "    elif labels_train_df[idx] == \"HTTP_DDoS\":\n",
    "        labels_train_df[idx] = 1\n",
    "    elif labels_train_df[idx] == \"ICMP_Flood\":\n",
    "        labels_train_df[idx] = 2\n",
    "    elif labels_train_df[idx] == \"Port_Scan\":\n",
    "        labels_train_df[idx] = 3\n",
    "    elif labels_train_df[idx] == \"Web_Crwling\":\n",
    "        labels_train_df[idx] = 4\n",
    "    elif labels_train_df[idx] == \"Normal\":\n",
    "        labels_train_df[idx] = 5\n",
    "\n",
    "labels_train_np = np.array(labels_train_df)\n",
    "\n",
    "features_val_np = np.array(features_val_df)\n",
    "\n",
    "for idx in range(len(labels_val_df)):\n",
    "    if labels_val_df[idx] == \"Brute_Force\":\n",
    "        labels_val_df[idx] = 0\n",
    "    elif labels_val_df[idx] == \"HTTP_DDoS\":\n",
    "        labels_val_df[idx] = 1\n",
    "    elif labels_val_df[idx] == \"ICMP_Flood\":\n",
    "        labels_val_df[idx] = 2\n",
    "    elif labels_val_df[idx] == \"Port_Scan\":\n",
    "        labels_val_df[idx] = 3\n",
    "    elif labels_val_df[idx] == \"Web_Crwling\":\n",
    "        labels_val_df[idx] = 4\n",
    "    elif labels_val_df[idx] == \"Normal\":\n",
    "        labels_val_df[idx] = 5\n",
    "\n",
    "\n",
    "\n",
    "labels_val_np = np.array(labels_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103036, 66)\n",
      "(103036,)\n",
      "(25763, 66)\n",
      "(25763,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_np.shape)\n",
    "print(labels_train_np.shape)\n",
    "print(features_val_np.shape)\n",
    "print(labels_val_np.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the train and val features and labels as .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train\"\n",
    "val_path = \"data/val\"\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "if not os.path.exists(val_path):\n",
    "    os.makedirs(val_path)  \n",
    "\n",
    "np.save(os.path.join(train_path, 'features.npy'), features_train_np)\n",
    "np.save(os.path.join(train_path, 'labels.npy'), labels_train_np)\n",
    "np.save(os.path.join(val_path, 'features.npy'), features_val_np)\n",
    "np.save(os.path.join(val_path, 'labels.npy'), labels_val_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EECS553_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16df7304af27907c212b6b9225288c2168f9d6c8050794d743717f5b29bb4446"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
